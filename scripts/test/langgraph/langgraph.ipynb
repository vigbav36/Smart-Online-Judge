{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "question = \"\"\"\n",
    "    Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n",
    "    You may assume that each input would have exactly one solution, and you may not use the same element twice.\n",
    "\n",
    "    You can return the answer in any order.\n",
    "\n",
    "    Input: nums = [2,7,11,15], target = 9\n",
    "    Output: [0,1]\n",
    "    Explanation: Because nums[0] + nums[1] == 9, we return [0, 1].\n",
    "\"\"\"\n",
    "\n",
    "expectedCode = \"\"\"class Solution:\n",
    "        def twoSum(self, nums: List[int], target: int) -> List[int]:\n",
    "            hashmap = {}\n",
    "            for i in range(len(nums)):\n",
    "                hashmap[nums[i]] = i\n",
    "            for i in range(len(nums)):\n",
    "                complement = target - nums[i]\n",
    "                if complement in hashmap and hashmap[complement] != i:\n",
    "                    return [i, hashmap[complement]]\n",
    "\n",
    "        \"\"\"\n",
    "expectedApproach = \"A simple implementation uses two iterations. In the first iteration, we add each element's value as a key and its index as a value to the hash table. Then, in the second iteration, we check if each element's complement (targetâˆ’nums[i]) exists in the hash table. If it does exist, we return current element's index and its complement's index. Beware that the complement must not be nums[i] itself!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the interview state object\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Phase(str, Enum):\n",
    "    INTRODUCTION = 'introduction'\n",
    "    QUESTION  = 'question'\n",
    "    APPROACH = 'approach'\n",
    "\n",
    "class PhaseModel(BaseModel):\n",
    "    phase : Literal['introduction', 'question', 'approach']\n",
    "    \n",
    "class Dialogue(BaseModel):\n",
    "    dialogue: str = Field(description=\"The dialogue\")\n",
    "    speaker: Literal['interviewer', 'candidate'] = Field(description=\"The speaker of the dialogue\")\n",
    "    \n",
    "class InterviewState(BaseModel):\n",
    "    \n",
    "    conversations: List[Dialogue] = Field(default_factory=list)\n",
    "    question: str = question\n",
    "    expectedApproach : str = expectedApproach\n",
    "    expectedCode : str = expectedCode\n",
    "\n",
    "    userCode : str = \"\"    \n",
    "    phase : Phase = Phase.INTRODUCTION\n",
    "    \n",
    "\n",
    "class IntroductionResponse(BaseModel):\n",
    "    dialogue : str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPrompt(filePath):\n",
    "    content = open(filePath).read()\n",
    "    return PromptTemplate.from_template(content)\n",
    "\n",
    "def getModel():\n",
    "    return  ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining nodes of the workflow\n",
    "\n",
    "def controlNode(state : InterviewState):\n",
    "    prompt = readPrompt(\"prompts\\control\\classifyConversation.txt\")\n",
    "    model = getModel()\n",
    "    chain = prompt | model.with_structured_output(PhaseModel)\n",
    "    response = chain.invoke({'conversations':state.conversations})\n",
    "    state.phase  =  Phase(response.phase)\n",
    "    return state.dict()\n",
    "    \n",
    "\n",
    "def introductionNode(state : InterviewState):\n",
    "\n",
    "    prompt = readPrompt(\"prompts\\introduction\\introduction.txt\")\n",
    "    model = getModel()\n",
    "\n",
    "    chain = prompt | model\n",
    "\n",
    "    response = chain.invoke({'conversations':state.conversations})\n",
    "    state.conversations.append(Dialogue(dialogue=str(response.content), speaker=\"INTERVIEWER\"))\n",
    "    \n",
    "    return state.dict()\n",
    "\n",
    "\n",
    "def describeQuestionNode(state : InterviewState):\n",
    "    prompt = readPrompt(\"prompts\\questions\\describeQuestion.txt\")\n",
    "    model = getModel()\n",
    "\n",
    "    chain = prompt | model\n",
    "\n",
    "    response = chain.invoke({'conversations':state.conversations, 'question':state.question})\n",
    "\n",
    "    state.conversations.append(Dialogue(dialogue=str(response.content), speaker=\"INTERVIEWER\"))\n",
    "    \n",
    "    return state.dict()\n",
    "\n",
    "\n",
    "def describeApproachNode(state : InterviewState):\n",
    "    prompt = readPrompt(\"prompts\\questions\\explainApproach.txt\")\n",
    "    model = getModel()\n",
    "\n",
    "    chain = prompt | model\n",
    "\n",
    "    response = chain.invoke({'conversations':state.conversations, 'question':state.question, 'expectedApproach':expectedApproach })\n",
    "\n",
    "    state.conversations.append(Dialogue(dialogue=str(response.content), speaker=\"INTERVIEWER\"))\n",
    "    \n",
    "    return state.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "\n",
    "def checkPhase(state: InterviewState) -> Literal[\"introductionNode\", \"describeQuestionNode\", \"describeApproachNode\", END]:\n",
    "  \n",
    "    if state.phase == Phase.INTRODUCTION :\n",
    "        return \"introductionNode\"\n",
    "    if state.phase == Phase.QUESTION:\n",
    "        return \"describeQuestionNode\"\n",
    "    if state.phase == Phase.APPROACH:\n",
    "        return \"describeApproachNode\"\n",
    "    \n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the graph\n",
    "\n",
    "workflow = StateGraph(InterviewState)\n",
    "\n",
    "workflow.add_node(\"controlNode\", controlNode)\n",
    "workflow.add_node(\"introductionNode\", introductionNode)\n",
    "workflow.add_node(\"describeQuestionNode\", describeQuestionNode)\n",
    "workflow.add_node(\"describeApproachNode\", describeApproachNode)\n",
    "\n",
    "workflow.add_edge(START, \"controlNode\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"controlNode\",\n",
    "    checkPhase,\n",
    ")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory : dict[str, InterviewState]= {'1' : InterviewState()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import VoiceSettings\n",
    "from elevenlabs.client import ElevenLabs\n",
    "import time\n",
    "\n",
    "def read_text(text):\n",
    "    client = ElevenLabs(\n",
    "        api_key=\"\",\n",
    "    )\n",
    "    response  = client.text_to_speech.convert(\n",
    "        voice_id=\"cjVigY5qzO86Huf0OWal\",\n",
    "        optimize_streaming_latency=\"0\",\n",
    "        output_format=\"mp3_22050_32\",\n",
    "        text=text,\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.1,\n",
    "            similarity_boost=0.3,\n",
    "            style=0.2,\n",
    "        ),\n",
    "    )\n",
    "    save_file_path = f\"output.mp3\"\n",
    "\n",
    "    with open(save_file_path, \"wb\") as f:\n",
    "        for chunk in response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    os.system(\"start output.mp3\") \n",
    "\n",
    "\n",
    "def process_user_input(user_input):\n",
    "    try:\n",
    "        state : InterviewState = memory['1']\n",
    "        state.conversations.append(Dialogue(dialogue=user_input, speaker=\"candidate\"))\n",
    "        finalState = graph.invoke(state)\n",
    "        memory['1'] = InterviewState(**finalState) \n",
    "        return memory['1']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def chat():\n",
    "    print(memory['1'])\n",
    "    while True:\n",
    "        user_input = input(\"\")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        response = process_user_input(user_input)\n",
    "        text = (response.conversations[len(response.conversations)-1].dialogue)\n",
    "        print(text)\n",
    "        #read_text(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
